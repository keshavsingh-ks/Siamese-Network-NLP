{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gm27YCIJa5wC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"questions.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JhNP2JJmbevn",
        "outputId": "a4bd1837-b14e-4378-ba78-27c92939600f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d31d3baa-313f-456f-8a84-74940ff28106\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d31d3baa-313f-456f-8a84-74940ff28106')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d31d3baa-313f-456f-8a84-74940ff28106 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d31d3baa-313f-456f-8a84-74940ff28106');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-210ad8f6-0f1b-4b90-b554-bd046bd553c3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-210ad8f6-0f1b-4b90-b554-bd046bd553c3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-210ad8f6-0f1b-4b90-b554-bd046bd553c3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_apcbuHIblxl",
        "outputId": "5bea64c1-9de6-4e61-d351-3c599570f7e0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "404351"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_train = 300000\n",
        "N_test = 10240\n",
        "data_train = df[:N_train]\n",
        "data_test = df[N_train:N_train + N_test]\n",
        "print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKh_x50Tb0Iz",
        "outputId": "71aa02dc-f82a-42aa-c01a-9ca1b41bdb9b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 300000 Test set: 10240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "z1Zf3MwMcego",
        "outputId": "1adc1294-77bf-445a-838f-0d0624c9c92e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  qid1  qid2                                          question1  \\\n",
              "0   0     1     2  What is the step by step guide to invest in sh...   \n",
              "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
              "2   2     5     6  How can I increase the speed of my internet co...   \n",
              "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
              "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
              "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
              "6   6    13    14                                Should I buy tiago?   \n",
              "7   7    15    16                     How can I be a good geologist?   \n",
              "8   8    17    18                    When do you use シ instead of し?   \n",
              "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
              "\n",
              "                                           question2  is_duplicate  \n",
              "0  What is the step by step guide to invest in sh...             0  \n",
              "1  What would happen if the Indian government sto...             0  \n",
              "2  How can Internet speed be increased by hacking...             0  \n",
              "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
              "4            Which fish would survive in salt water?             0  \n",
              "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
              "6  What keeps childern active and far from phone ...             0  \n",
              "7          What should I do to be a great geologist?             1  \n",
              "8              When do you use \"&\" instead of \"and\"?             0  \n",
              "9  How do I hack Motorola DCX3400 for free internet?             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fbc4f521-2001-4a98-953e-647022285f60\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "      <td>How can Internet speed be increased by hacking...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
              "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
              "      <td>Which fish would survive in salt water?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
              "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>Should I buy tiago?</td>\n",
              "      <td>What keeps childern active and far from phone ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "      <td>How can I be a good geologist?</td>\n",
              "      <td>What should I do to be a great geologist?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17</td>\n",
              "      <td>18</td>\n",
              "      <td>When do you use シ instead of し?</td>\n",
              "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>19</td>\n",
              "      <td>20</td>\n",
              "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
              "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fbc4f521-2001-4a98-953e-647022285f60')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fbc4f521-2001-4a98-953e-647022285f60 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fbc4f521-2001-4a98-953e-647022285f60');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-19052495-3731-49e2-a683-53dba2b422a5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19052495-3731-49e2-a683-53dba2b422a5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-19052495-3731-49e2-a683-53dba2b422a5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_train"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "td_index = data_train['is_duplicate'] == 1\n",
        "td_index = [i for i, x in enumerate(td_index) if x]\n",
        "print('Number of duplicate questions: ', len(td_index))\n",
        "print('Indexes of first ten duplicate questions:', td_index[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fDE8tO3rkkx",
        "outputId": "05119ad0-7869-4f0b-b314-cbbddd6f362e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate questions:  111486\n",
            "Indexes of first ten duplicate questions: [5, 7, 11, 12, 13, 15, 16, 18, 20, 29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data_train['question1'][5])\n",
        "print(data_train['question2'][5])\n",
        "print('is_duplicate: ', data_train['is_duplicate'][5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1e7l_8xrw6e",
        "outputId": "912fd327-ad6d-4012-ed82-e767e15cc101"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?\n",
            "I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\n",
            "is_duplicate:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q1_train = np.array(data_train['question1'][td_index])\n",
        "Q2_train = np.array(data_train['question2'][td_index])\n",
        "Q1_test = np.array(data_test['question1'])\n",
        "Q2_test = np.array(data_test['question2'])"
      ],
      "metadata": {
        "id": "r0iqhs39sAes"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = np.array(data_test['is_duplicate'])"
      ],
      "metadata": {
        "id": "hnzBhWq5sXfK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cut_off = int(len(Q1_train) * 0.8)\n",
        "train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n",
        "val_Q1, val_Q2 = Q1_train[cut_off:], Q2_train[cut_off:]\n",
        "print('Number of duplicate questions: ', len(Q1_train))\n",
        "print(\"The length of the training set is:  \", len(train_Q1))\n",
        "print(\"The length of the validation set is: \", len(val_Q1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKmb_1qZsb2C",
        "outputId": "beb786d5-18d1-47af-a76f-06abbb1f6467"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of duplicate questions:  111486\n",
            "The length of the training set is:   89188\n",
            "The length of the validation set is:  22298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from posixpath import split\n",
        "tf.random.set_seed(1)\n",
        "text_vectorizer= tf.keras.layers.TextVectorization(\n",
        "    output_mode='int',\n",
        "    split='whitespace',\n",
        "    ngrams=None,\n",
        "    standardize = 'strip_punctuation',\n",
        ")\n",
        "text_vectorizer.adapt(np.concatenate([train_Q1, train_Q2]))"
      ],
      "metadata": {
        "id": "IQOiKQ4IsoJI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = text_vectorizer.get_vocabulary()\n",
        "print(len(vocab), vocab[:20])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3--3erPtoLp",
        "outputId": "61e89487-1263-4327-af81-bf6b18fd14ee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32819 ['', '[UNK]', 'the', 'What', 'How', 'is', 'I', 'to', 'do', 'in', 'a', 'of', 'are', 'and', 'can', 'you', 'best', 'for', 'Why', 'my']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('first question in the train set:\\n')\n",
        "print(Q1_train[0], '\\n')\n",
        "print('encoded version:')\n",
        "print(text_vectorizer(Q1_train[0]),'\\n')\n",
        "\n",
        "print('first question in the test set:\\n')\n",
        "print(Q1_test[0], '\\n')\n",
        "print('encoded version:')\n",
        "print(text_vectorizer(Q1_test[0]) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVPx5ReQt5Uo",
        "outputId": "c4ac96c3-498d-4188-a95a-c21c7aa5181e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first question in the train set:\n",
            "\n",
            "Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me? \n",
            "\n",
            "encoded version:\n",
            "tf.Tensor(\n",
            "[ 6123     6   178    10  9079  2220 32055   788    13  6047 25433    30\n",
            "    28   463    45    98], shape=(16,), dtype=int64) \n",
            "\n",
            "first question in the test set:\n",
            "\n",
            "How do I prepare for interviews for cse? \n",
            "\n",
            "encoded version:\n",
            "tf.Tensor([    4     8     6   157    17  1909    17 11616], shape=(8,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import name\n",
        "def siamese_model(text_vectorizer, vocab_size = 32819, d_features = 128):\n",
        "\n",
        "  branch = tf.keras.models.Sequential(name='sequential')\n",
        "  branch.add(text_vectorizer)\n",
        "  branch.add(tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=d_features, name='embedding'))\n",
        "  branch.add(tf.keras.layers.LSTM(d_features, return_sequences=True))\n",
        "  branch.add(tf.keras.layers.GlobalAveragePooling1D(name='mean'))\n",
        "  branch.add(tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x))),\n",
        "\n",
        "  input1 = tf.keras.Input(name='input_1', shape=(1,), dtype=tf.string)\n",
        "  input2 = tf.keras.Input(name='input_2', shape=(1,), dtype=tf.string)\n",
        "\n",
        "\n",
        "  branch1 = branch(input1)\n",
        "  branch2 = branch(input2)\n",
        "\n",
        "  merged = tf.keras.layers.concatenate([branch1, branch2], axis=-1, name='merged_layer')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return tf.keras.models.Model(inputs=[input1, input2], outputs=merged, name='siamese_model')"
      ],
      "metadata": {
        "id": "NaseZEMDvdBZ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(tf.keras.models.Model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "whpTjlOu1E-2",
        "outputId": "244352c5-706d-4b76-f883-d9253c64e42f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class Model in module keras.src.models.model:\n",
            "\n",
            "class Model(keras.src.backend.tensorflow.trainer.TensorFlowTrainer, keras.src.trainers.trainer.Trainer, keras.src.layers.layer.Layer)\n",
            " |  Model(*args, **kwargs)\n",
            " |  \n",
            " |  A model grouping layers into an object with training/inference features.\n",
            " |  \n",
            " |  There are three ways to instantiate a `Model`:\n",
            " |  \n",
            " |  ## With the \"Functional API\"\n",
            " |  \n",
            " |  You start from `Input`,\n",
            " |  you chain layer calls to specify the model's forward pass,\n",
            " |  and finally, you create your model from inputs and outputs:\n",
            " |  \n",
            " |  ```python\n",
            " |  inputs = keras.Input(shape=(37,))\n",
            " |  x = keras.layers.Dense(32, activation=\"relu\")(inputs)\n",
            " |  outputs = keras.layers.Dense(5, activation=\"softmax\")(x)\n",
            " |  model = keras.Model(inputs=inputs, outputs=outputs)\n",
            " |  ```\n",
            " |  \n",
            " |  Note: Only dicts, lists, and tuples of input tensors are supported. Nested\n",
            " |  inputs are not supported (e.g. lists of list or dicts of dict).\n",
            " |  \n",
            " |  A new Functional API model can also be created by using the\n",
            " |  intermediate tensors. This enables you to quickly extract sub-components\n",
            " |  of the model.\n",
            " |  \n",
            " |  Example:\n",
            " |  \n",
            " |  ```python\n",
            " |  inputs = keras.Input(shape=(None, None, 3))\n",
            " |  processed = keras.layers.RandomCrop(width=128, height=128)(inputs)\n",
            " |  conv = keras.layers.Conv2D(filters=32, kernel_size=3)(processed)\n",
            " |  pooling = keras.layers.GlobalAveragePooling2D()(conv)\n",
            " |  feature = keras.layers.Dense(10)(pooling)\n",
            " |  \n",
            " |  full_model = keras.Model(inputs, feature)\n",
            " |  backbone = keras.Model(processed, conv)\n",
            " |  activations = keras.Model(conv, feature)\n",
            " |  ```\n",
            " |  \n",
            " |  Note that the `backbone` and `activations` models are not\n",
            " |  created with `keras.Input` objects, but with the tensors that originate\n",
            " |  from `keras.Input` objects. Under the hood, the layers and weights will\n",
            " |  be shared across these models, so that user can train the `full_model`, and\n",
            " |  use `backbone` or `activations` to do feature extraction.\n",
            " |  The inputs and outputs of the model can be nested structures of tensors as\n",
            " |  well, and the created models are standard Functional API models that support\n",
            " |  all the existing APIs.\n",
            " |  \n",
            " |  ## By subclassing the `Model` class\n",
            " |  \n",
            " |  In that case, you should define your\n",
            " |  layers in `__init__()` and you should implement the model's forward pass\n",
            " |  in `call()`.\n",
            " |  \n",
            " |  ```python\n",
            " |  class MyModel(keras.Model):\n",
            " |      def __init__(self):\n",
            " |          super().__init__()\n",
            " |          self.dense1 = keras.layers.Dense(32, activation=\"relu\")\n",
            " |          self.dense2 = keras.layers.Dense(5, activation=\"softmax\")\n",
            " |  \n",
            " |      def call(self, inputs):\n",
            " |          x = self.dense1(inputs)\n",
            " |          return self.dense2(x)\n",
            " |  \n",
            " |  model = MyModel()\n",
            " |  ```\n",
            " |  \n",
            " |  If you subclass `Model`, you can optionally have\n",
            " |  a `training` argument (boolean) in `call()`, which you can use to specify\n",
            " |  a different behavior in training and inference:\n",
            " |  \n",
            " |  ```python\n",
            " |  class MyModel(keras.Model):\n",
            " |      def __init__(self):\n",
            " |          super().__init__()\n",
            " |          self.dense1 = keras.layers.Dense(32, activation=\"relu\")\n",
            " |          self.dense2 = keras.layers.Dense(5, activation=\"softmax\")\n",
            " |          self.dropout = keras.layers.Dropout(0.5)\n",
            " |  \n",
            " |      def call(self, inputs, training=False):\n",
            " |          x = self.dense1(inputs)\n",
            " |          x = self.dropout(x, training=training)\n",
            " |          return self.dense2(x)\n",
            " |  \n",
            " |  model = MyModel()\n",
            " |  ```\n",
            " |  \n",
            " |  Once the model is created, you can config the model with losses and metrics\n",
            " |  with `model.compile()`, train the model with `model.fit()`, or use the model\n",
            " |  to do prediction with `model.predict()`.\n",
            " |  \n",
            " |  ## With the `Sequential` class\n",
            " |  \n",
            " |  In addition, `keras.Sequential` is a special case of model where\n",
            " |  the model is purely a stack of single-input, single-output layers.\n",
            " |  \n",
            " |  ```python\n",
            " |  model = keras.Sequential([\n",
            " |      keras.Input(shape=(None, None, 3)),\n",
            " |      keras.layers.Conv2D(filters=32, kernel_size=3),\n",
            " |  ])\n",
            " |  ```\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Model\n",
            " |      keras.src.backend.tensorflow.trainer.TensorFlowTrainer\n",
            " |      keras.src.trainers.trainer.Trainer\n",
            " |      keras.src.layers.layer.Layer\n",
            " |      keras.src.backend.tensorflow.layer.TFLayer\n",
            " |      keras.src.backend.tensorflow.trackable.KerasAutoTrackable\n",
            " |      tensorflow.python.trackable.autotrackable.AutoTrackable\n",
            " |      tensorflow.python.trackable.base.Trackable\n",
            " |      keras.src.ops.operation.Operation\n",
            " |      keras.src.saving.keras_saveable.KerasSaveable\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, *args, **kwargs)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  build_from_config(self, config)\n",
            " |      Builds the layer's states with the supplied config dict.\n",
            " |      \n",
            " |      By default, this method calls the `build(config[\"input_shape\"])` method,\n",
            " |      which creates weights based on the layer's input shape in the supplied\n",
            " |      config. If your config contains other information needed to load the\n",
            " |      layer's state, you should override this method.\n",
            " |      \n",
            " |      Args:\n",
            " |          config: Dict containing the input shape associated with this layer.\n",
            " |  \n",
            " |  call(self, *args, **kwargs)\n",
            " |  \n",
            " |  export(self, filepath, format='tf_saved_model')\n",
            " |      Create a TF SavedModel artifact for inference.\n",
            " |      \n",
            " |      **Note:** This can currently only be used with\n",
            " |      the TensorFlow or JAX backends.\n",
            " |      \n",
            " |      This method lets you export a model to a lightweight SavedModel artifact\n",
            " |      that contains the model's forward pass only (its `call()` method)\n",
            " |      and can be served via e.g. TF-Serving. The forward pass is registered\n",
            " |      under the name `serve()` (see example below).\n",
            " |      \n",
            " |      The original code of the model (including any custom layers you may\n",
            " |      have used) is *no longer* necessary to reload the artifact -- it is\n",
            " |      entirely standalone.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: `str` or `pathlib.Path` object. Path where to save\n",
            " |              the artifact.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      # Create the artifact\n",
            " |      model.export(\"path/to/location\")\n",
            " |      \n",
            " |      # Later, in a different process/environment...\n",
            " |      reloaded_artifact = tf.saved_model.load(\"path/to/location\")\n",
            " |      predictions = reloaded_artifact.serve(input_data)\n",
            " |      ```\n",
            " |      \n",
            " |      If you would like to customize your serving endpoints, you can\n",
            " |      use the lower-level `keras.export.ExportArchive` class. The\n",
            " |      `export()` method relies on `ExportArchive` internally.\n",
            " |  \n",
            " |  get_layer(self, name=None, index=None)\n",
            " |      Retrieves a layer based on either its name (unique) or index.\n",
            " |      \n",
            " |      If `name` and `index` are both provided, `index` will take precedence.\n",
            " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
            " |      \n",
            " |      Args:\n",
            " |          name: String, name of layer.\n",
            " |          index: Integer, index of layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  load_weights(self, filepath, skip_mismatch=False, **kwargs)\n",
            " |      Load weights from a file saved via `save_weights()`.\n",
            " |      \n",
            " |      Weights are loaded based on the network's\n",
            " |      topology. This means the architecture should be the same as when the\n",
            " |      weights were saved. Note that layers that don't have weights are not\n",
            " |      taken into account in the topological ordering, so adding or removing\n",
            " |      layers is fine as long as they don't have weights.\n",
            " |      \n",
            " |      **Partial weight loading**\n",
            " |      \n",
            " |      If you have modified your model, for instance by adding a new layer\n",
            " |      (with weights) or by changing the shape of the weights of a layer,\n",
            " |      you can choose to ignore errors and continue loading\n",
            " |      by setting `skip_mismatch=True`. In this case any layer with\n",
            " |      mismatching weights will be skipped. A warning will be displayed\n",
            " |      for each skipped layer.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: String, path to the weights file to load.\n",
            " |              It can either be a `.weights.h5` file\n",
            " |              or a legacy `.h5` weights file.\n",
            " |          skip_mismatch: Boolean, whether to skip loading of layers where\n",
            " |              there is a mismatch in the number of weights, or a mismatch in\n",
            " |              the shape of the weights.\n",
            " |  \n",
            " |  quantize(self, mode)\n",
            " |      Quantize the weights of the model.\n",
            " |      \n",
            " |      Note that the model must be built first before calling this method.\n",
            " |      `quantize` will recursively call `quantize(mode)` in all layers and\n",
            " |      will be skipped if the layer doesn't implement the function.\n",
            " |      \n",
            " |      Args:\n",
            " |          mode: The mode of the quantization. Only 'int8' is supported at this\n",
            " |              time.\n",
            " |  \n",
            " |  save(self, filepath, overwrite=True, zipped=True, **kwargs)\n",
            " |      Saves a model as a `.keras` file.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: `str` or `pathlib.Path` object.\n",
            " |              The path where to save the model. Must end in `.keras`\n",
            " |              (unless saving the model as an unzipped directory\n",
            " |              via `zipped=False`).\n",
            " |          overwrite: Whether we should overwrite any existing model at\n",
            " |              the target location, or instead ask the user via\n",
            " |              an interactive prompt.\n",
            " |          zipped: Whether to save the model as a zipped `.keras`\n",
            " |              archive (default), or as an unzipped directory.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      model = keras.Sequential(\n",
            " |          [\n",
            " |              keras.layers.Dense(5, input_shape=(3,)),\n",
            " |              keras.layers.Softmax(),\n",
            " |          ],\n",
            " |      )\n",
            " |      model.save(\"model.keras\")\n",
            " |      loaded_model = keras.saving.load_model(\"model.keras\")\n",
            " |      x = keras.random.uniform((10, 3))\n",
            " |      assert np.allclose(model.predict(x), loaded_model.predict(x))\n",
            " |      ```\n",
            " |      \n",
            " |      Note that `model.save()` is an alias for `keras.saving.save_model()`.\n",
            " |      \n",
            " |      The saved `.keras` file contains:\n",
            " |      \n",
            " |      - The model's configuration (architecture)\n",
            " |      - The model's weights\n",
            " |      - The model's optimizer's state (if any)\n",
            " |      \n",
            " |      Thus models can be reinstantiated in the exact same state.\n",
            " |  \n",
            " |  save_weights(self, filepath, overwrite=True)\n",
            " |      Saves all layer weights to a `.weights.h5` file.\n",
            " |      \n",
            " |      Args:\n",
            " |          filepath: `str` or `pathlib.Path` object.\n",
            " |              Path where to save the model. Must end in `.weights.h5`.\n",
            " |          overwrite: Whether we should overwrite any existing model\n",
            " |              at the target location, or instead ask the user\n",
            " |              via an interactive prompt.\n",
            " |  \n",
            " |  summary(self, line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False, layer_range=None)\n",
            " |      Prints a string summary of the network.\n",
            " |      \n",
            " |      Args:\n",
            " |          line_length: Total length of printed lines\n",
            " |              (e.g. set this to adapt the display to different\n",
            " |              terminal window sizes).\n",
            " |          positions: Relative or absolute positions of log elements\n",
            " |              in each line. If not provided, becomes\n",
            " |              `[0.3, 0.6, 0.70, 1.]`. Defaults to `None`.\n",
            " |          print_fn: Print function to use. By default, prints to `stdout`.\n",
            " |              If `stdout` doesn't work in your environment, change to `print`.\n",
            " |              It will be called on each line of the summary.\n",
            " |              You can set it to a custom function\n",
            " |              in order to capture the string summary.\n",
            " |          expand_nested: Whether to expand the nested models.\n",
            " |              Defaults to `False`.\n",
            " |          show_trainable: Whether to show if a layer is trainable.\n",
            " |              Defaults to `False`.\n",
            " |          layer_range: a list or tuple of 2 strings,\n",
            " |              which is the starting layer name and ending layer name\n",
            " |              (both inclusive) indicating the range of layers to be printed\n",
            " |              in summary. It also accepts regex patterns instead of exact\n",
            " |              names. In this case, the start predicate will be\n",
            " |              the first element that matches `layer_range[0]`\n",
            " |              and the end predicate will be the last element\n",
            " |              that matches `layer_range[1]`.\n",
            " |              By default `None` considers all layers of the model.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if `summary()` is called before the model is built.\n",
            " |  \n",
            " |  to_json(self, **kwargs)\n",
            " |      Returns a JSON string containing the network configuration.\n",
            " |      \n",
            " |      To load a network from a JSON save file, use\n",
            " |      `keras.models.model_from_json(json_string, custom_objects={...})`.\n",
            " |      \n",
            " |      Args:\n",
            " |          **kwargs: Additional keyword arguments to be passed to\n",
            " |              `json.dumps()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A JSON string.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods defined here:\n",
            " |  \n",
            " |  from_config(config, custom_objects=None) from builtins.type\n",
            " |      Creates an operation from its config.\n",
            " |      \n",
            " |      This method is the reverse of `get_config`, capable of instantiating the\n",
            " |      same operation from the config dictionary.\n",
            " |      \n",
            " |      Note: If you override this method, you might receive a serialized dtype\n",
            " |      config, which is a `dict`. You can deserialize it as follows:\n",
            " |      \n",
            " |      ```python\n",
            " |      if \"dtype\" in config and isinstance(config[\"dtype\"], dict):\n",
            " |          policy = dtype_policies.deserialize(config[\"dtype\"])\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          config: A Python dictionary, typically the output of `get_config`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An operation instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  layers\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.src.backend.tensorflow.trainer.TensorFlowTrainer:\n",
            " |  \n",
            " |  compiled_loss(self, y, y_pred, sample_weight=None, regularization_losses=None)\n",
            " |  \n",
            " |  evaluate(self, x=None, y=None, batch_size=None, verbose='auto', sample_weight=None, steps=None, callbacks=None, return_dict=False, **kwargs)\n",
            " |      Returns the loss value & metrics values for the model in test mode.\n",
            " |      \n",
            " |      Computation is done in batches (see the `batch_size` arg.)\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |              - A NumPy array (or array-like), or a list of arrays\n",
            " |                  (in case the model has multiple inputs).\n",
            " |              - A tensor, or a list of tensors\n",
            " |                  (in case the model has multiple inputs).\n",
            " |              - A dict mapping input names to the corresponding array/tensors,\n",
            " |                  if the model has named inputs.\n",
            " |              - A `tf.data.Dataset`. Should return a tuple\n",
            " |                  of either `(inputs, targets)` or\n",
            " |                  `(inputs, targets, sample_weights)`.\n",
            " |              - A generator or `keras.utils.PyDataset` returning\n",
            " |                  `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
            " |          y: Target data. Like the input data `x`, it could be either NumPy\n",
            " |              array(s) or backend-native tensor(s).\n",
            " |              If `x` is a `tf.data.Dataset` or `keras.utils.PyDataset`\n",
            " |              instance, `y` should not be specified\n",
            " |              (since targets will be obtained from the iterator/dataset).\n",
            " |          batch_size: Integer or `None`. Number of samples per batch of\n",
            " |              computation. If unspecified, `batch_size` will default to 32. Do\n",
            " |              not specify the `batch_size` if your data is in the form of a\n",
            " |              dataset, generators, or `keras.utils.PyDataset` instances\n",
            " |              (since they generate batches).\n",
            " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = single line.\n",
            " |              `\"auto\"` becomes 1 for most cases.\n",
            " |              Note that the progress bar is not\n",
            " |              particularly useful when logged to a file, so `verbose=2` is\n",
            " |              recommended when not running interactively\n",
            " |              (e.g. in a production environment). Defaults to `\"auto\"`.\n",
            " |          sample_weight: Optional NumPy array of weights for the test samples,\n",
            " |              used for weighting the loss function. You can either pass a flat\n",
            " |              (1D) NumPy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples), or in the case of\n",
            " |              temporal data, you can pass a 2D array with shape `(samples,\n",
            " |              sequence_length)`, to apply a different weight to every\n",
            " |              timestep of every sample. This argument is not supported when\n",
            " |              `x` is a dataset, instead pass sample weights as the third\n",
            " |              element of `x`.\n",
            " |          steps: Integer or `None`. Total number of steps (batches of samples)\n",
            " |              before declaring the evaluation round finished. Ignored with the\n",
            " |              default value of `None`. If `x` is a `tf.data.Dataset` and\n",
            " |              `steps` is `None`, evaluation will run until the dataset\n",
            " |              is exhausted.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during evaluation.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a\n",
            " |              dict, with each key being the name of the metric.\n",
            " |              If `False`, they are returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Scalar test loss (if the model has a single output and no metrics)\n",
            " |          or list of scalars (if the model has multiple outputs\n",
            " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
            " |          the display labels for the scalar outputs.\n",
            " |  \n",
            " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose='auto', callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1)\n",
            " |      Trains the model for a fixed number of epochs (dataset iterations).\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It could be:\n",
            " |              - A NumPy array (or array-like), or a list of arrays\n",
            " |              (in case the model has multiple inputs).\n",
            " |              - A tensor, or a list of tensors\n",
            " |              (in case the model has multiple inputs).\n",
            " |              - A dict mapping input names to the corresponding array/tensors,\n",
            " |              if the model has named inputs.\n",
            " |              - A `tf.data.Dataset`. Should return a tuple\n",
            " |              of either `(inputs, targets)` or\n",
            " |              `(inputs, targets, sample_weights)`.\n",
            " |              - A `keras.utils.PyDataset` returning `(inputs,\n",
            " |              targets)` or `(inputs, targets, sample_weights)`.\n",
            " |          y: Target data. Like the input data `x`,\n",
            " |              it could be either NumPy array(s) or backend-native tensor(s).\n",
            " |              If `x` is a dataset, generator,\n",
            " |              or `keras.utils.PyDataset` instance, `y` should\n",
            " |              not be specified (since targets will be obtained from `x`).\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per gradient update.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.PyDataset`\n",
            " |              instances (since they generate batches).\n",
            " |          epochs: Integer. Number of epochs to train the model.\n",
            " |              An epoch is an iteration over the entire `x` and `y`\n",
            " |              data provided\n",
            " |              (unless the `steps_per_epoch` flag is set to\n",
            " |              something other than None).\n",
            " |              Note that in conjunction with `initial_epoch`,\n",
            " |              `epochs` is to be understood as \"final epoch\".\n",
            " |              The model is not trained for a number of iterations\n",
            " |              given by `epochs`, but merely until the epoch\n",
            " |              of index `epochs` is reached.\n",
            " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
            " |              \"auto\" becomes 1 for most cases.\n",
            " |              Note that the progress bar is not\n",
            " |              particularly useful when logged to a file,\n",
            " |              so `verbose=2` is recommended when not running interactively\n",
            " |              (e.g., in a production environment). Defaults to `\"auto\"`.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during training.\n",
            " |              See `keras.callbacks`. Note\n",
            " |              `keras.callbacks.ProgbarLogger` and\n",
            " |              `keras.callbacks.History` callbacks are created\n",
            " |              automatically and need not be passed to `model.fit()`.\n",
            " |              `keras.callbacks.ProgbarLogger` is created\n",
            " |              or not based on the `verbose` argument in `model.fit()`.\n",
            " |          validation_split: Float between 0 and 1.\n",
            " |              Fraction of the training data to be used as validation data.\n",
            " |              The model will set apart this fraction of the training data,\n",
            " |              will not train on it, and will evaluate\n",
            " |              the loss and any model metrics\n",
            " |              on this data at the end of each epoch.\n",
            " |              The validation data is selected from the last samples\n",
            " |              in the `x` and `y` data provided, before shuffling. This\n",
            " |              argument is not supported when `x` is a dataset, generator or\n",
            " |              `keras.utils.PyDataset` instance.\n",
            " |              If both `validation_data` and `validation_split` are provided,\n",
            " |              `validation_data` will override `validation_split`.\n",
            " |          validation_data: Data on which to evaluate\n",
            " |              the loss and any model metrics at the end of each epoch.\n",
            " |              The model will not be trained on this data. Thus, note the fact\n",
            " |              that the validation loss of data provided using\n",
            " |              `validation_split` or `validation_data` is not affected by\n",
            " |              regularization layers like noise and dropout.\n",
            " |              `validation_data` will override `validation_split`.\n",
            " |              It could be:\n",
            " |              - A tuple `(x_val, y_val)` of NumPy arrays or tensors.\n",
            " |              - A tuple `(x_val, y_val, val_sample_weights)` of NumPy\n",
            " |              arrays.\n",
            " |              - A `tf.data.Dataset`.\n",
            " |              - A Python generator or `keras.utils.PyDataset` returning\n",
            " |              `(inputs, targets)` or `(inputs, targets, sample_weights)`.\n",
            " |          shuffle: Boolean, whether to shuffle the training data\n",
            " |              before each epoch. This argument is\n",
            " |              ignored when `x` is a generator or a `tf.data.Dataset`.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers)\n",
            " |              to a weight (float) value, used for weighting the loss function\n",
            " |              (during training only).\n",
            " |              This can be useful to tell the model to\n",
            " |              \"pay more attention\" to samples from\n",
            " |              an under-represented class. When `class_weight` is specified\n",
            " |              and targets have a rank of 2 or greater, either `y` must be\n",
            " |              one-hot encoded, or an explicit final dimension of `1` must\n",
            " |              be included for sparse class labels.\n",
            " |          sample_weight: Optional NumPy array of weights for\n",
            " |              the training samples, used for weighting the loss function\n",
            " |              (during training only). You can either pass a flat (1D)\n",
            " |              NumPy array with the same length as the input samples\n",
            " |              (1:1 mapping between weights and samples),\n",
            " |              or in the case of temporal data,\n",
            " |              you can pass a 2D array with shape\n",
            " |              `(samples, sequence_length)`,\n",
            " |              to apply a different weight to every timestep of every sample.\n",
            " |              This argument is not supported when `x` is a dataset, generator,\n",
            " |              or `keras.utils.PyDataset` instance, instead provide the\n",
            " |              sample_weights as the third element of `x`.\n",
            " |              Note that sample weighting does not apply to metrics specified\n",
            " |              via the `metrics` argument in `compile()`. To apply sample\n",
            " |              weighting to your metrics, you can specify them via the\n",
            " |              `weighted_metrics` in `compile()` instead.\n",
            " |          initial_epoch: Integer.\n",
            " |              Epoch at which to start training\n",
            " |              (useful for resuming a previous training run).\n",
            " |          steps_per_epoch: Integer or `None`.\n",
            " |              Total number of steps (batches of samples)\n",
            " |              before declaring one epoch finished and starting the\n",
            " |              next epoch. When training with input tensors such as\n",
            " |              backend-native tensors, the default `None` is equal to\n",
            " |              the number of samples in your dataset divided by\n",
            " |              the batch size, or 1 if that cannot be determined. If `x` is a\n",
            " |              `tf.data.Dataset`, and `steps_per_epoch`\n",
            " |              is `None`, the epoch will run until the input dataset is\n",
            " |              exhausted.  When passing an infinitely repeating dataset, you\n",
            " |              must specify the `steps_per_epoch` argument. If\n",
            " |              `steps_per_epoch=-1` the training will run indefinitely with an\n",
            " |              infinitely repeating dataset.\n",
            " |          validation_steps: Only relevant if `validation_data` is provided.\n",
            " |              Total number of steps (batches of\n",
            " |              samples) to draw before stopping when performing validation\n",
            " |              at the end of every epoch. If `validation_steps` is `None`,\n",
            " |              validation will run until the `validation_data` dataset is\n",
            " |              exhausted. In the case of an infinitely repeated dataset, it\n",
            " |              will run into an infinite loop. If `validation_steps` is\n",
            " |              specified and only part of the dataset will be consumed, the\n",
            " |              evaluation will start from the beginning of the dataset at each\n",
            " |              epoch. This ensures that the same validation samples are used\n",
            " |              every time.\n",
            " |          validation_batch_size: Integer or `None`.\n",
            " |              Number of samples per validation batch.\n",
            " |              If unspecified, will default to `batch_size`.\n",
            " |              Do not specify the `validation_batch_size` if your data is in\n",
            " |              the form of datasets or `keras.utils.PyDataset`\n",
            " |              instances (since they generate batches).\n",
            " |          validation_freq: Only relevant if validation data is provided.\n",
            " |              Specifies how many training epochs to run\n",
            " |              before a new validation run is performed,\n",
            " |              e.g. `validation_freq=2` runs validation every 2 epochs.\n",
            " |      \n",
            " |      Unpacking behavior for iterator-like inputs:\n",
            " |          A common pattern is to pass an iterator like object such as a\n",
            " |          `tf.data.Dataset` or a `keras.utils.PyDataset` to `fit()`,\n",
            " |          which will in fact yield not only features (`x`)\n",
            " |          but optionally targets (`y`) and sample weights (`sample_weight`).\n",
            " |          Keras requires that the output of such iterator-likes be\n",
            " |          unambiguous. The iterator should return a tuple\n",
            " |          of length 1, 2, or 3, where the optional second and third elements\n",
            " |          will be used for `y` and `sample_weight` respectively.\n",
            " |          Any other type provided will be wrapped in\n",
            " |          a length-one tuple, effectively treating everything as `x`. When\n",
            " |          yielding dicts, they should still adhere to the top-level tuple\n",
            " |          structure,\n",
            " |          e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
            " |          features, targets, and weights from the keys of a single dict.\n",
            " |          A notable unsupported data type is the `namedtuple`. The reason is\n",
            " |          that it behaves like both an ordered datatype (tuple) and a mapping\n",
            " |          datatype (dict). So given a namedtuple of the form:\n",
            " |          `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
            " |          it is ambiguous whether to reverse the order of the elements when\n",
            " |          interpreting the value. Even worse is a tuple of the form:\n",
            " |          `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
            " |          where it is unclear if the tuple was intended to be unpacked\n",
            " |          into `x`, `y`, and `sample_weight` or passed through\n",
            " |          as a single element to `x`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `History` object. Its `History.history` attribute is\n",
            " |          a record of training loss values and metrics values\n",
            " |          at successive epochs, as well as validation loss values\n",
            " |          and validation metrics values (if applicable).\n",
            " |  \n",
            " |  loss(self, y, y_pred, sample_weight=None)\n",
            " |  \n",
            " |  make_predict_function(self, force=False)\n",
            " |  \n",
            " |  make_test_function(self, force=False)\n",
            " |  \n",
            " |  make_train_function(self, force=False)\n",
            " |  \n",
            " |  predict(self, x, batch_size=None, verbose='auto', steps=None, callbacks=None)\n",
            " |      Generates output predictions for the input samples.\n",
            " |      \n",
            " |      Computation is done in batches. This method is designed for batch\n",
            " |      processing of large numbers of inputs. It is not intended for use inside\n",
            " |      of loops that iterate over your data and process small numbers of inputs\n",
            " |      at a time.\n",
            " |      \n",
            " |      For small numbers of inputs that fit in one batch,\n",
            " |      directly use `__call__()` for faster execution, e.g.,\n",
            " |      `model(x)`, or `model(x, training=False)` if you have layers such as\n",
            " |      `BatchNormalization` that behave differently during\n",
            " |      inference.\n",
            " |      \n",
            " |      Note: See [this FAQ entry](\n",
            " |      https://keras.io/getting_started/faq/#whats-the-difference-between-model-methods-predict-and-call)\n",
            " |      for more details about the difference between `Model` methods\n",
            " |      `predict()` and `__call__()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input samples. It could be:\n",
            " |              - A NumPy array (or array-like), or a list of arrays\n",
            " |                  (in case the model has multiple inputs).\n",
            " |              - A tensor, or a list of tensors\n",
            " |                  (in case the model has multiple inputs).\n",
            " |              - A `tf.data.Dataset`.\n",
            " |              - A `keras.utils.PyDataset` instance.\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per batch.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of dataset, generators, or `keras.utils.PyDataset`\n",
            " |              instances (since they generate batches).\n",
            " |          verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\n",
            " |              0 = silent, 1 = progress bar, 2 = single line.\n",
            " |              `\"auto\"` becomes 1 for most cases. Note that the progress bar\n",
            " |              is not particularly useful when logged to a file,\n",
            " |              so `verbose=2` is recommended when not running interactively\n",
            " |              (e.g. in a production environment). Defaults to `\"auto\"`.\n",
            " |          steps: Total number of steps (batches of samples)\n",
            " |              before declaring the prediction round finished.\n",
            " |              Ignored with the default value of `None`.\n",
            " |              If `x` is a `tf.data.Dataset` and `steps` is `None`,\n",
            " |              `predict()` will run until the input dataset is exhausted.\n",
            " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
            " |              List of callbacks to apply during prediction.\n",
            " |      \n",
            " |      Returns:\n",
            " |          NumPy array(s) of predictions.\n",
            " |  \n",
            " |  predict_on_batch(self, x)\n",
            " |      Returns predictions for a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. It must be array-like.\n",
            " |      \n",
            " |      Returns:\n",
            " |          NumPy array(s) of predictions.\n",
            " |  \n",
            " |  predict_step(self, data)\n",
            " |  \n",
            " |  test_on_batch(self, x, y=None, sample_weight=None, return_dict=False)\n",
            " |      Test the model on a single batch of samples.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. Must be array-like.\n",
            " |          y: Target data. Must be array-like.\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |              weights to apply to the model's loss for each sample.\n",
            " |              In the case of temporal data, you can pass a 2D array\n",
            " |              with shape `(samples, sequence_length)`, to apply a different\n",
            " |              weight to every timestep of every sample.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a\n",
            " |              dict, with each key being the name of the metric. If `False`,\n",
            " |              they are returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A scalar loss value (when no metrics and `return_dict=False`),\n",
            " |          a list of loss and metric values\n",
            " |          (if there are metrics and `return_dict=False`), or a dict of\n",
            " |          metric and loss values (if `return_dict=True`).\n",
            " |  \n",
            " |  test_step(self, data)\n",
            " |  \n",
            " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, return_dict=False)\n",
            " |      Runs a single gradient update on a single batch of data.\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data. Must be array-like.\n",
            " |          y: Target data. Must be array-like.\n",
            " |          sample_weight: Optional array of the same length as x, containing\n",
            " |              weights to apply to the model's loss for each sample.\n",
            " |              In the case of temporal data, you can pass a 2D array\n",
            " |              with shape `(samples, sequence_length)`, to apply a different\n",
            " |              weight to every timestep of every sample.\n",
            " |          class_weight: Optional dictionary mapping class indices (integers)\n",
            " |              to a weight (float) to apply to the model's loss for the samples\n",
            " |              from this class during training. This can be useful to tell the\n",
            " |              model to \"pay more attention\" to samples from an\n",
            " |              under-represented class. When `class_weight` is specified\n",
            " |              and targets have a rank of 2 or greater, either `y` must\n",
            " |              be one-hot encoded, or an explicit final dimension of 1\n",
            " |              must be included for sparse class labels.\n",
            " |          return_dict: If `True`, loss and metric results are returned as a\n",
            " |              dict, with each key being the name of the metric. If `False`,\n",
            " |              they are returned as a list.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A scalar loss value (when no metrics and `return_dict=False`),\n",
            " |          a list of loss and metric values\n",
            " |          (if there are metrics and `return_dict=False`), or a dict of\n",
            " |          metric and loss values (if `return_dict=True`).\n",
            " |  \n",
            " |  train_step(self, data)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.src.backend.tensorflow.trainer.TensorFlowTrainer:\n",
            " |  \n",
            " |  compiled_metrics\n",
            " |  \n",
            " |  distribute_strategy\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.src.backend.tensorflow.trainer.TensorFlowTrainer:\n",
            " |  \n",
            " |  distribute_reduction_method\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.src.trainers.trainer.Trainer:\n",
            " |  \n",
            " |  compile(self, optimizer='rmsprop', loss=None, loss_weights=None, metrics=None, weighted_metrics=None, run_eagerly=False, steps_per_execution=1, jit_compile='auto', auto_scale_loss=True)\n",
            " |      Configures the model for training.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      model.compile(\n",
            " |          optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
            " |          loss=keras.losses.BinaryCrossentropy(),\n",
            " |          metrics=[\n",
            " |              keras.metrics.BinaryAccuracy(),\n",
            " |              keras.metrics.FalseNegatives(),\n",
            " |          ],\n",
            " |      )\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          optimizer: String (name of optimizer) or optimizer instance. See\n",
            " |              `keras.optimizers`.\n",
            " |          loss: Loss function. May be a string (name of loss function), or\n",
            " |              a `keras.losses.Loss` instance. See `keras.losses`. A\n",
            " |              loss function is any callable with the signature\n",
            " |              `loss = fn(y_true, y_pred)`, where `y_true` are the ground truth\n",
            " |              values, and `y_pred` are the model's predictions.\n",
            " |              `y_true` should have shape `(batch_size, d0, .. dN)`\n",
            " |              (except in the case of sparse loss functions such as\n",
            " |              sparse categorical crossentropy which expects integer arrays of\n",
            " |              shape `(batch_size, d0, .. dN-1)`).\n",
            " |              `y_pred` should have shape `(batch_size, d0, .. dN)`.\n",
            " |              The loss function should return a float tensor.\n",
            " |          loss_weights: Optional list or dictionary specifying scalar\n",
            " |              coefficients (Python floats) to weight the loss contributions of\n",
            " |              different model outputs. The loss value that will be minimized\n",
            " |              by the model will then be the *weighted sum* of all individual\n",
            " |              losses, weighted by the `loss_weights` coefficients.  If a list,\n",
            " |              it is expected to have a 1:1 mapping to the model's outputs. If\n",
            " |              a dict, it is expected to map output names (strings) to scalar\n",
            " |              coefficients.\n",
            " |          metrics: List of metrics to be evaluated by the model during\n",
            " |              training and testing. Each of this can be a string (name of a\n",
            " |              built-in function), function or a `keras.metrics.Metric`\n",
            " |              instance. See `keras.metrics`. Typically you will use\n",
            " |              `metrics=['accuracy']`. A function is any callable with the\n",
            " |              signature `result = fn(y_true, _pred)`. To specify different\n",
            " |              metrics for different outputs of a multi-output model, you could\n",
            " |              also pass a dictionary, such as\n",
            " |              `metrics={'a':'accuracy', 'b':['accuracy', 'mse']}`.\n",
            " |              You can also pass a list to specify a metric or a list of\n",
            " |              metrics for each output, such as\n",
            " |              `metrics=[['accuracy'], ['accuracy', 'mse']]`\n",
            " |              or `metrics=['accuracy', ['accuracy', 'mse']]`. When you pass\n",
            " |              the strings 'accuracy' or 'acc', we convert this to one of\n",
            " |              `keras.metrics.BinaryAccuracy`,\n",
            " |              `keras.metrics.CategoricalAccuracy`,\n",
            " |              `keras.metrics.SparseCategoricalAccuracy` based on the\n",
            " |              shapes of the targets and of the model output. A similar\n",
            " |              conversion is done for the strings `\"crossentropy\"`\n",
            " |              and `\"ce\"` as well.\n",
            " |              The metrics passed here are evaluated without sample weighting;\n",
            " |              if you would like sample weighting to apply, you can specify\n",
            " |              your metrics via the `weighted_metrics` argument instead.\n",
            " |          weighted_metrics: List of metrics to be evaluated and weighted by\n",
            " |              `sample_weight` or `class_weight` during training and testing.\n",
            " |          run_eagerly: Bool. If `True`, this model's forward pass\n",
            " |               will never be compiled. It is recommended to leave this\n",
            " |               as `False` when training (for best performance),\n",
            " |               and to set it to `True` when debugging.\n",
            " |          steps_per_execution: Int. The number of batches to run\n",
            " |              during each a single compiled function call. Running multiple\n",
            " |              batches inside a single compiled function call can\n",
            " |              greatly improve performance on TPUs or small models with a large\n",
            " |              Python overhead. At most, one full epoch will be run each\n",
            " |              execution. If a number larger than the size of the epoch is\n",
            " |              passed, the execution will be truncated to the size of the\n",
            " |              epoch. Note that if `steps_per_execution` is set to `N`,\n",
            " |              `Callback.on_batch_begin` and `Callback.on_batch_end` methods\n",
            " |              will only be called every `N` batches (i.e. before/after\n",
            " |              each compiled function execution).\n",
            " |              Not supported with the PyTorch backend.\n",
            " |          jit_compile: Bool or `\"auto\"`. Whether to use XLA compilation when\n",
            " |              compiling a model. For `jax` and `tensorflow` backends,\n",
            " |              `jit_compile=\"auto\"` enables XLA compilation if the model\n",
            " |              supports it, and disabled otherwise.\n",
            " |              For `torch` backend, `\"auto\"` will default to eager\n",
            " |              execution and `jit_compile=True` will run with `torch.compile`\n",
            " |              with the `\"inductor\"` backend.\n",
            " |          auto_scale_loss: Bool. If `True` and the model dtype policy is\n",
            " |              `\"mixed_float16\"`, the passed optimizer will be automatically\n",
            " |              wrapped in a `LossScaleOptimizer`, which will dynamically\n",
            " |              scale the loss to prevent underflow.\n",
            " |  \n",
            " |  compile_from_config(self, config)\n",
            " |      Compiles the model with the information given in config.\n",
            " |      \n",
            " |      This method uses the information in the config (optimizer, loss,\n",
            " |      metrics, etc.) to compile the model.\n",
            " |      \n",
            " |      Args:\n",
            " |          config: Dict containing information for compiling the model.\n",
            " |  \n",
            " |  compute_loss(self, x=None, y=None, y_pred=None, sample_weight=None, training=True)\n",
            " |      Compute the total loss, validate it, and return it.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom loss\n",
            " |      computation logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyModel(Model):\n",
            " |          def __init__(self, *args, **kwargs):\n",
            " |              super().__init__(*args, **kwargs)\n",
            " |              self.loss_tracker = metrics.Mean(name='loss')\n",
            " |      \n",
            " |          def compute_loss(self, x, y, y_pred, sample_weight, training=True):\n",
            " |              loss = ops.means((y_pred - y) ** 2)\n",
            " |              loss += ops.sum(self.losses)\n",
            " |              self.loss_tracker.update_state(loss)\n",
            " |              return loss\n",
            " |      \n",
            " |          def reset_metrics(self):\n",
            " |              self.loss_tracker.reset_state()\n",
            " |      \n",
            " |          @property\n",
            " |          def metrics(self):\n",
            " |              return [self.loss_tracker]\n",
            " |      \n",
            " |      inputs = layers.Input(shape=(10,), name='my_input')\n",
            " |      outputs = layers.Dense(10)(inputs)\n",
            " |      model = MyModel(inputs, outputs)\n",
            " |      model.add_loss(ops.sum(outputs))\n",
            " |      \n",
            " |      optimizer = SGD()\n",
            " |      model.compile(optimizer, loss='mse', steps_per_execution=10)\n",
            " |      dataset = ...\n",
            " |      model.fit(dataset, epochs=2, steps_per_epoch=10)\n",
            " |      print(f\"Custom loss: {model.loss_tracker.result()}\")\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data.\n",
            " |          y: Target data.\n",
            " |          y_pred: Predictions returned by the model (output of `model(x)`)\n",
            " |          sample_weight: Sample weights for weighting the loss function.\n",
            " |          training: Whether we are training or evaluating the model.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The total loss as a scalar tensor, or `None` if no loss results\n",
            " |          (which is the case when called by `Model.test_step`).\n",
            " |  \n",
            " |  compute_metrics(self, x, y, y_pred, sample_weight=None)\n",
            " |      Update metric states and collect all metrics to be returned.\n",
            " |      \n",
            " |      Subclasses can optionally override this method to provide custom metric\n",
            " |      updating and collection logic.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyModel(Sequential):\n",
            " |          def compute_metrics(self, x, y, y_pred, sample_weight):\n",
            " |              # This super call updates `self.compiled_metrics` and returns\n",
            " |              # results for all metrics listed in `self.metrics`.\n",
            " |              metric_results = super().compute_metrics(\n",
            " |                  x, y, y_pred, sample_weight)\n",
            " |      \n",
            " |              # Note that `self.custom_metric` is not listed\n",
            " |              # in `self.metrics`.\n",
            " |              self.custom_metric.update_state(x, y, y_pred, sample_weight)\n",
            " |              metric_results['metric_name'] = self.custom_metric.result()\n",
            " |              return metric_results\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          x: Input data.\n",
            " |          y: Target data.\n",
            " |          y_pred: Predictions returned by the model output of `model.call(x)`.\n",
            " |          sample_weight: Sample weights for weighting the loss function.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `dict` containing values that will be passed to\n",
            " |          `keras.callbacks.CallbackList.on_train_batch_end()`. Typically,\n",
            " |          the values of the metrics listed in `self.metrics` are returned.\n",
            " |          Example: `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  get_compile_config(self)\n",
            " |      Returns a serialized config with information for compiling the model.\n",
            " |      \n",
            " |      This method returns a config dictionary containing all the information\n",
            " |      (optimizer, loss, metrics, etc.) with which the model was compiled.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A dict containing information for compiling the model.\n",
            " |  \n",
            " |  get_metrics_result(self)\n",
            " |      Returns the model's metrics values as a dict.\n",
            " |      \n",
            " |      If any of the metric result is a dict (containing multiple metrics),\n",
            " |      each of them gets added to the top level returned dict of this method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A `dict` containing values of the metrics listed in `self.metrics`.\n",
            " |          Example: `{'loss': 0.2, 'accuracy': 0.7}`.\n",
            " |  \n",
            " |  reset_metrics(self)\n",
            " |  \n",
            " |  stateless_compute_loss(self, trainable_variables, non_trainable_variables, metrics_variables, x=None, y=None, y_pred=None, sample_weight=None, training=True)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.src.trainers.trainer.Trainer:\n",
            " |  \n",
            " |  metrics\n",
            " |  \n",
            " |  metrics_names\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.src.trainers.trainer.Trainer:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  jit_compile\n",
            " |  \n",
            " |  run_eagerly\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.src.layers.layer.Layer:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |      Call self as a function.\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  __str__(self)\n",
            " |      Return str(self).\n",
            " |  \n",
            " |  add_loss(self, loss)\n",
            " |      Can be called inside of the `call()` method to add a scalar loss.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(Layer):\n",
            " |          ...\n",
            " |          def call(self, x):\n",
            " |              self.add_loss(ops.sum(x))\n",
            " |              return x\n",
            " |      ```\n",
            " |  \n",
            " |  add_metric(self)\n",
            " |  \n",
            " |  add_variable(self, shape, initializer, dtype=None, trainable=True, autocast=True, regularizer=None, constraint=None, name=None)\n",
            " |      Add a weight variable to the layer.\n",
            " |      \n",
            " |      Alias of `add_weight()`.\n",
            " |  \n",
            " |  add_weight(self, shape=None, initializer=None, dtype=None, trainable=True, autocast=True, regularizer=None, constraint=None, aggregation='mean', name=None)\n",
            " |      Add a weight variable to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |          shape: Shape tuple for the variable. Must be fully-defined\n",
            " |              (no `None` entries). Defaults to `()` (scalar) if unspecified.\n",
            " |          initializer: Initializer object to use to populate the initial\n",
            " |              variable value, or string name of a built-in initializer\n",
            " |              (e.g. `\"random_normal\"`). If unspecified, defaults to\n",
            " |              `\"glorot_uniform\"` for floating-point variables and to `\"zeros\"`\n",
            " |              for all other types (e.g. int, bool).\n",
            " |          dtype: Dtype of the variable to create, e.g. `\"float32\"`. If\n",
            " |              unspecified, defaults to the layer's variable dtype\n",
            " |              (which itself defaults to `\"float32\"` if unspecified).\n",
            " |          trainable: Boolean, whether the variable should be trainable via\n",
            " |              backprop or whether its updates are managed manually. Defaults\n",
            " |              to `True`.\n",
            " |          autocast: Boolean, whether to autocast layers variables when\n",
            " |              accessing them. Defaults to `True`.\n",
            " |          regularizer: Regularizer object to call to apply penalty on the\n",
            " |              weight. These penalties are summed into the loss function\n",
            " |              during optimization. Defaults to `None`.\n",
            " |          constraint: Contrainst object to call on the variable after any\n",
            " |              optimizer update, or string name of a built-in constraint.\n",
            " |              Defaults to `None`.\n",
            " |          aggregation: String, one of `'mean'`, `'sum'`,\n",
            " |              `'only_first_replica'`. Annotates the variable with the type\n",
            " |              of multi-replica aggregation to be used for this variable\n",
            " |              when writing custom data parallel training loops.\n",
            " |          name: String name of the variable. Useful for debugging purposes.\n",
            " |  \n",
            " |  build(self, input_shape)\n",
            " |  \n",
            " |  compute_mask(self, inputs, previous_mask)\n",
            " |  \n",
            " |  compute_output_shape(self, *args, **kwargs)\n",
            " |  \n",
            " |  compute_output_spec(self, *args, **kwargs)\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |  \n",
            " |  get_build_config(self)\n",
            " |      Returns a dictionary with the layer's input shape.\n",
            " |      \n",
            " |      This method returns a config dict that can be used by\n",
            " |      `build_from_config(config)` to create all states (e.g. Variables and\n",
            " |      Lookup tables) needed by the layer.\n",
            " |      \n",
            " |      By default, the config only contains the input shape that the layer\n",
            " |      was built with. If you're writing a custom layer that creates state in\n",
            " |      an unusual way, you should override this method to make sure this state\n",
            " |      is already created when Keras attempts to load its value upon model\n",
            " |      loading.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A dict containing the input shape associated with the layer.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the object.\n",
            " |      \n",
            " |      An object config is a Python dictionary (serializable)\n",
            " |      containing the information needed to re-instantiate it.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Return the values of `layer.weights` as a list of NumPy arrays.\n",
            " |  \n",
            " |  load_own_variables(self, store)\n",
            " |      Loads the state of the layer.\n",
            " |      \n",
            " |      You can override this method to take full control of how the state of\n",
            " |      the layer is loaded upon calling `keras.models.load_model()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          store: Dict from which the state of the model will be loaded.\n",
            " |  \n",
            " |  quantized_call(self, *args, **kwargs)\n",
            " |  \n",
            " |  save_own_variables(self, store)\n",
            " |      Saves the state of the layer.\n",
            " |      \n",
            " |      You can override this method to take full control of how the state of\n",
            " |      the layer is saved upon calling `model.save()`.\n",
            " |      \n",
            " |      Args:\n",
            " |          store: Dict where the state of the model will be saved.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the values of `layer.weights` from a list of NumPy arrays.\n",
            " |  \n",
            " |  stateless_call(self, trainable_variables, non_trainable_variables, *args, return_losses=False, **kwargs)\n",
            " |      Call the layer without any side effects.\n",
            " |      \n",
            " |      Args:\n",
            " |          trainable_variables: List of trainable variables of the model.\n",
            " |          non_trainable_variables: List of non-trainable variables of the\n",
            " |              model.\n",
            " |          *args: Positional arguments to be passed to `call()`.\n",
            " |          return_losses: If `True`, `stateless_call()` will return the list of\n",
            " |              losses created during `call()` as part of its return values.\n",
            " |          **kwargs: Keyword arguments to be passed to `call()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tuple. By default, returns `(outputs, non_trainable_variables)`.\n",
            " |              If `return_losses = True`, then returns\n",
            " |              `(outputs, non_trainable_variables, losses)`.\n",
            " |      \n",
            " |      Note: `non_trainable_variables` include not only non-trainable weights\n",
            " |      such as `BatchNormalization` statistics, but also RNG seed state\n",
            " |      (if there are any random operations part of the layer, such as dropout),\n",
            " |      and `Metric` state (if there are any metrics attached to the layer).\n",
            " |      These are all elements of state of the layer.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      model = ...\n",
            " |      data = ...\n",
            " |      trainable_variables = model.trainable_variables\n",
            " |      non_trainable_variables = model.non_trainable_variables\n",
            " |      # Call the model with zero side effects\n",
            " |      outputs, non_trainable_variables = model.stateless_call(\n",
            " |          trainable_variables,\n",
            " |          non_trainable_variables,\n",
            " |          data,\n",
            " |      )\n",
            " |      # Attach the updated state to the model\n",
            " |      # (until you do this, the model is still in its pre-call state).\n",
            " |      for ref_var, value in zip(\n",
            " |          model.non_trainable_variables, non_trainable_variables\n",
            " |      ):\n",
            " |          ref_var.assign(value)\n",
            " |      ```\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.src.layers.layer.Layer:\n",
            " |  \n",
            " |  compute_dtype\n",
            " |      The dtype of the computations performed by the layer.\n",
            " |  \n",
            " |  dtype\n",
            " |      Alias of `layer.variable_dtype`.\n",
            " |  \n",
            " |  input_dtype\n",
            " |      The dtype layer inputs should be converted to.\n",
            " |  \n",
            " |  losses\n",
            " |      List of scalar losses from `add_loss`, regularizers and sublayers.\n",
            " |  \n",
            " |  metrics_variables\n",
            " |      List of all metric variables.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |      List of all non-trainable layer state.\n",
            " |      \n",
            " |      This extends `layer.non_trainable_weights` to include all state used by\n",
            " |      the layer including state for metrics and `SeedGenerator`s.\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weight variables of the layer.\n",
            " |      \n",
            " |      These are the weights that should not be updated by the optimizer during\n",
            " |      training. Unlike, `layer.non_trainable_variables` this excludes metric\n",
            " |      state and random seeds.\n",
            " |  \n",
            " |  path\n",
            " |      The path of the layer.\n",
            " |      \n",
            " |      If the layer has not been built yet, it will be `None`.\n",
            " |  \n",
            " |  quantization_mode\n",
            " |      The quantization mode of this layer, `None` if not quantized.\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      List of all trainable layer state.\n",
            " |      \n",
            " |      This is equivalent to `layer.trainable_weights`.\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weight variables of the layer.\n",
            " |      \n",
            " |      These are the weights that get updated by the optimizer during training.\n",
            " |  \n",
            " |  variable_dtype\n",
            " |      The dtype of the state (weights) of the layer.\n",
            " |  \n",
            " |  variables\n",
            " |      List of all layer state, including random seeds.\n",
            " |      \n",
            " |      This extends `layer.weights` to include all state used by the layer\n",
            " |      including `SeedGenerator`s.\n",
            " |      \n",
            " |      Note that metrics variables are not included here, use\n",
            " |      `metrics_variables` to visit all the metric variables.\n",
            " |  \n",
            " |  weights\n",
            " |      List of all weight variables of the layer.\n",
            " |      \n",
            " |      Unlike, `layer.variables` this excludes metric state and random seeds.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.src.layers.layer.Layer:\n",
            " |  \n",
            " |  dtype_policy\n",
            " |  \n",
            " |  input_spec\n",
            " |  \n",
            " |  supports_masking\n",
            " |      Whether this layer supports computing a mask using `compute_mask`.\n",
            " |  \n",
            " |  trainable\n",
            " |      Settable boolean, whether this layer should be trainable or not.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from tensorflow.python.trackable.autotrackable.AutoTrackable:\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.src.ops.operation.Operation:\n",
            " |  \n",
            " |  symbolic_call(self, *args, **kwargs)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.src.ops.operation.Operation:\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a symbolic operation.\n",
            " |      \n",
            " |      Only returns the tensor(s) corresponding to the *first time*\n",
            " |      the operation was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only returns the tensor(s) corresponding to the *first time*\n",
            " |      the operation was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output tensor or list of output tensors.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.src.saving.keras_saveable.KerasSaveable:\n",
            " |  \n",
            " |  __reduce__(self)\n",
            " |      __reduce__ is used to customize the behavior of `pickle.pickle()`.\n",
            " |      \n",
            " |      The method returns a tuple of two elements: a function, and a list of\n",
            " |      arguments to pass to that function.  In this case we just leverage the\n",
            " |      keras saving library.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = siamese_model(text_vectorizer, vocab_size=text_vectorizer.vocabulary_size())\n",
        "model.build(input_shape=None)\n",
        "model.summary()\n",
        "model.get_layer('sequential').summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "id": "_rSlj8Mt1Fxl",
        "outputId": "6ad48f4a-0fbb-4593-c601-d414dd2196f4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"siamese_model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"siamese_model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential (\u001b[38;5;33mSequential\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │      \u001b[38;5;34m4,332,416\u001b[0m │ input_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ input_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ merged_layer              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ sequential[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,332,416</span> │ input_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ input_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ merged_layer              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,332,416\u001b[0m (16.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,332,416</span> (16.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,332,416\u001b[0m (16.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,332,416</span> (16.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization_2                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │       \u001b[38;5;34m4,200,832\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ mean (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda_9 (\u001b[38;5;33mLambda\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ text_vectorization_2                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)                  │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,200,832</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lambda_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,332,416\u001b[0m (16.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,332,416</span> (16.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,332,416\u001b[0m (16.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,332,416</span> (16.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=True,\n",
        "    show_dtype=True,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "1tDzHOYb3iws",
        "outputId": "1814873e-5068-43a2-f46d-96d30706e951"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(tf.transpose)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hxnUHsT8-xG8",
        "outputId": "79d3af1b-45a5-470d-dc3b-dbf4fd494146"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function transpose_v2 in module tensorflow.python.ops.array_ops:\n",
            "\n",
            "transpose_v2(a, perm=None, conjugate=False, name='transpose')\n",
            "    Transposes `a`, where `a` is a Tensor.\n",
            "    \n",
            "    Permutes the dimensions according to the value of `perm`.\n",
            "    \n",
            "    The returned tensor's dimension `i` will correspond to the input dimension\n",
            "    `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is the rank\n",
            "    of the input tensor. Hence, by default, this operation performs a regular\n",
            "    matrix transpose on 2-D input Tensors.\n",
            "    \n",
            "    If conjugate is `True` and `a.dtype` is either `complex64` or `complex128`\n",
            "    then the values of `a` are conjugated and transposed.\n",
            "    \n",
            "    @compatibility(numpy)\n",
            "    In `numpy` transposes are memory-efficient constant time operations as they\n",
            "    simply return a new view of the same data with adjusted `strides`.\n",
            "    \n",
            "    TensorFlow does not support strides, so `transpose` returns a new tensor with\n",
            "    the items permuted.\n",
            "    @end_compatibility\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
            "    >>> tf.transpose(x)\n",
            "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
            "    array([[1, 4],\n",
            "           [2, 5],\n",
            "           [3, 6]], dtype=int32)>\n",
            "    \n",
            "    Equivalently, you could call `tf.transpose(x, perm=[1, 0])`.\n",
            "    \n",
            "    If `x` is complex, setting conjugate=True gives the conjugate transpose:\n",
            "    \n",
            "    >>> x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
            "    ...                  [4 + 4j, 5 + 5j, 6 + 6j]])\n",
            "    >>> tf.transpose(x, conjugate=True)\n",
            "    <tf.Tensor: shape=(3, 2), dtype=complex128, numpy=\n",
            "    array([[1.-1.j, 4.-4.j],\n",
            "           [2.-2.j, 5.-5.j],\n",
            "           [3.-3.j, 6.-6.j]])>\n",
            "    \n",
            "    'perm' is more useful for n-dimensional tensors where n > 2:\n",
            "    \n",
            "    >>> x = tf.constant([[[ 1,  2,  3],\n",
            "    ...                   [ 4,  5,  6]],\n",
            "    ...                  [[ 7,  8,  9],\n",
            "    ...                   [10, 11, 12]]])\n",
            "    \n",
            "    As above, simply calling `tf.transpose` will default to `perm=[2,1,0]`.\n",
            "    \n",
            "    To take the transpose of the matrices in dimension-0 (such as when you are\n",
            "    transposing matrices where 0 is the batch dimension), you would set\n",
            "    `perm=[0,2,1]`.\n",
            "    \n",
            "    >>> tf.transpose(x, perm=[0, 2, 1])\n",
            "    <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
            "    array([[[ 1,  4],\n",
            "            [ 2,  5],\n",
            "            [ 3,  6]],\n",
            "            [[ 7, 10],\n",
            "            [ 8, 11],\n",
            "            [ 9, 12]]], dtype=int32)>\n",
            "    \n",
            "    Note: This has a shorthand `linalg.matrix_transpose`):\n",
            "    \n",
            "    Args:\n",
            "      a: A `Tensor`.\n",
            "      perm: A permutation of the dimensions of `a`.  This should be a vector.\n",
            "      conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
            "        to tf.math.conj(tf.transpose(input)).\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A transposed `Tensor`.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def TripletLossFn(v1, v2,  margin=0.25):\n",
        "\n",
        "    scores = tf.linalg.matmul(v2, v1, transpose_b=True)\n",
        "\n",
        "    # calculate new batch size and cast it as the same datatype as scores.\n",
        "    batch_size = tf.cast(tf.shape(v1)[0], scores.dtype)\n",
        "\n",
        "    positive = tf.linalg.diag_part(scores)\n",
        "\n",
        "    negative_zero_on_duplicate = scores - tf.linalg.diag(positive)\n",
        "\n",
        "    mean_negative = tf.math.reduce_sum(negative_zero_on_duplicate, axis=1) / (batch_size - 1)\n",
        "\n",
        "    mask_exclude_positives = tf.cast((tf.eye(tf.shape(v1)[0]) == 1) | (negative_zero_on_duplicate > tf.expand_dims(positive, 1)), scores.dtype)\n",
        "\n",
        "    negative_without_positive = negative_zero_on_duplicate - (mask_exclude_positives * 2.0)\n",
        "\n",
        "    # take the row by row `max` of `negative_without_positive`.\n",
        "    closest_negative = tf.math.reduce_max(negative_without_positive, axis=1)\n",
        "\n",
        "    # A = subtract `positive` from `margin` and add `closest_negative`\n",
        "    triplet_loss1 = tf.maximum(0.0, margin - positive + closest_negative)\n",
        "    triplet_loss2 = tf.maximum(0.0, margin - positive + mean_negative)\n",
        "    triplet_loss = tf.math.reduce_sum(triplet_loss1 + triplet_loss2)\n",
        "\n",
        "\n",
        "    return triplet_loss"
      ],
      "metadata": {
        "id": "dTtbl9ws4L7U"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v1 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n",
        "v2 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\n",
        "print(\"Triplet Loss:\", TripletLossFn(v1,v2).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjQqYx94-EU3",
        "outputId": "44d547ae-5fd7-4708-f212-2c8f64d0b8df"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Triplet Loss: 0.7035076825158911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def TripletLoss(labels, out, margin=0.25):\n",
        "    _, embedding_size = out.shape # get embedding size\n",
        "    v1 = out[:,:int(embedding_size/2)] # Extract v1 from out\n",
        "    v2 = out[:,int(embedding_size/2):] # Extract v2 from out\n",
        "    return TripletLossFn(v1, v2, margin=margin)"
      ],
      "metadata": {
        "id": "K9c7Xw4XEahc"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(((train_Q1, train_Q2),tf.constant([1]*len(train_Q1))))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices(((val_Q1, val_Q2),tf.constant([1]*len(val_Q1))))"
      ],
      "metadata": {
        "id": "916goSxEEeRQ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(Siamese, TripletLoss, text_vectorizer, train_dataset, val_dataset, d_feature=128, lr=0.01, train_steps=5):\n",
        "\n",
        "    model = Siamese(text_vectorizer,\n",
        "                    vocab_size = len(vocab), #set vocab_size accordingly to the size of your vocabulary\n",
        "                    d_features = d_feature)\n",
        "\n",
        "    model.compile(loss=TripletLoss,\n",
        "                  optimizer = tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "            )\n",
        "\n",
        "    model.fit(train_dataset,\n",
        "              epochs = train_steps,\n",
        "              validation_data = val_dataset,\n",
        "             )\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "lacSVPb8E7Ve"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnythvW_Fo8_",
        "outputId": "091aad3f-7110-4ada-e756-69e1c0f3e51d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32819"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "train_generator = train_dataset.shuffle(len(train_Q1),\n",
        "                                        seed=7,\n",
        "                                        reshuffle_each_iteration=True).batch(batch_size=batch_size)\n",
        "val_generator = val_dataset.shuffle(len(val_Q1),\n",
        "                                   seed=7,\n",
        "                                   reshuffle_each_iteration=True).batch(batch_size=batch_size)\n",
        "model = train_model(siamese_model, TripletLoss,text_vectorizer,\n",
        "                                            train_generator,\n",
        "                                            val_generator,\n",
        "                                            )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJzlNGF_Fp_J",
        "outputId": "3c48a285-a904-4cbe-d671-9e96be73e263"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 483ms/step - loss: 127.1997 - val_loss: 126.4804\n",
            "Epoch 2/5\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 477ms/step - loss: 126.5474 - val_loss: 126.3624\n",
            "Epoch 3/5\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 474ms/step - loss: 126.4448 - val_loss: 126.3198\n",
            "Epoch 4/5\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 490ms/step - loss: 126.4268 - val_loss: 126.3235\n",
            "Epoch 5/5\n",
            "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 470ms/step - loss: 126.4069 - val_loss: 126.2792\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(test_Q1, test_Q2, y_test, threshold, model, batch_size=64, verbose=True):\n",
        "\n",
        "    y_pred = []\n",
        "    test_gen = tf.data.Dataset.from_tensor_slices(((test_Q1, test_Q2),None)).batch(batch_size=batch_size)\n",
        "\n",
        "\n",
        "    pred = model.predict(test_gen)\n",
        "    _, n_feat = pred.shape\n",
        "    v1 = pred[:, :int(n_feat / 2)]\n",
        "    v2 = pred[:, int(n_feat / 2):]\n",
        "\n",
        "    # Normalize v1 and v2 to get unit vectors for cosine similarity\n",
        "    v1_norm = tf.linalg.l2_normalize(v1, axis=1)\n",
        "    v2_norm = tf.linalg.l2_normalize(v2, axis=1)\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    d = tf.reduce_sum(v1_norm * v2_norm, axis=1)\n",
        "\n",
        "    # Check if d > threshold to make predictions\n",
        "    y_pred = tf.cast(d > threshold, tf.float64)\n",
        "\n",
        "    # Take the average of correct predictions to get the accuracy\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(y_pred, y_test), tf.float64))\n",
        "\n",
        "    # Compute the confusion matrix using `tf.math.confusion_matrix`\n",
        "    cm = tf.math.confusion_matrix(tf.cast(y_test, tf.int32), tf.cast(y_pred, tf.int32))\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return accuracy, cm\n"
      ],
      "metadata": {
        "id": "jJE-UMQdN6iT"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, cm = classify(Q1_test,Q2_test, y_test, 0.7, model,  batch_size = 512)\n",
        "print(\"Accuracy\", accuracy.numpy())\n",
        "print(f\"Confusion matrix:\\n{cm.numpy()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df1EyylXPXB-",
        "outputId": "01cfc7ed-df89-483c-c2b7-30eb60d4a1de"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 382ms/step\n",
            "Accuracy 0.66357421875\n",
            "Confusion matrix:\n",
            "[[3968 2414]\n",
            " [1031 2827]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(question1, question2, threshold, model, verbose=False):\n",
        "\n",
        "    generator = tf.data.Dataset.from_tensor_slices((([question1], [question2]),None)).batch(batch_size=1)\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Call the predict method of your model and save the output into v1v2\n",
        "    v1v2 = model.predict(generator)\n",
        "    embedding_size = v1v2.shape[1] // 2  # Divide by 2 as it contains both embeddings\n",
        "\n",
        "    # Extract v1 and v2 from the model output\n",
        "    v1 = v1v2[:, :embedding_size]  # First half of the embedding\n",
        "    v2 = v1v2[:, embedding_size:]\n",
        "    # Take the dot product to compute cos similarity of each pair of entries, v1, v2\n",
        "    # Since v1 and v2 are both vectors, use the function tf.math.reduce_sum instead of tf.linalg.matmul\n",
        "    d = tf.math.reduce_sum(v1 * v2, axis=1)\n",
        "    # Is d greater than the threshold?\n",
        "    res = tf.cast(d > threshold, tf.float64)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    if(verbose):\n",
        "        print(\"Q1  = \", question1, \"\\nQ2  = \", question2)\n",
        "        print(\"d   = \", d.numpy())\n",
        "        print(\"res = \", res.numpy())\n",
        "\n",
        "    return res.numpy()"
      ],
      "metadata": {
        "id": "rUBiIMIhPiWF"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YFg28aolQ-5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question1 = \"When will I see you?\"\n",
        "question2 = \"When can I see you again?\"\n",
        "# 1 means it is duplicated, 0 otherwise\n",
        "predict(question1 , question2, 0.7, model, verbose = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09BsT56FQaiS",
        "outputId": "88c094cc-369b-41ac-d397-19f4a96258eb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Q1  =  When will I see you? \n",
            "Q2  =  When can I see you again?\n",
            "d   =  [0.98898417]\n",
            "res =  [1.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question1 = \"Do they enjoy eating the dessert?\"\n",
        "question2 = \"Do they like hiking in the desert?\"\n",
        "# 1 means it is duplicated, 0 otherwise\n",
        "predict(question1 , question2, 0.7, model, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0omcY9OQ_hR",
        "outputId": "7cd577c2-a89b-40bd-8cb3-600ab6e771f9"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Q1  =  Do they enjoy eating the dessert? \n",
            "Q2  =  Do they like hiking in the desert?\n",
            "d   =  [-0.00178196]\n",
            "res =  [0.]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    }
  ]
}